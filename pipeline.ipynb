{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from googleapiclient.discovery import build\n",
    "import gspread\n",
    "from httplib2 import Http\n",
    "from oauth2client import file, client, tools\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import pandas as pd\n",
    "from itertools import islice\n",
    "import re\n",
    "from lxml import etree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key takeaways\n",
    "\n",
    "* Use British-English right from the beginning\n",
    "* Force the people to be responsible for their stuff\n",
    "* Force the people to work on mendeley\n",
    "* Force the people to use harvard citation\n",
    "* Force the people to write texts with the roughly the same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does this script work?!\n",
    "\n",
    "* The order of the trends is done by the order of the trends_intro and then by the inner order of the groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "## Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BULLET_ICON = \"\" # e.g. \"•\"\n",
    "\n",
    "# Abbreviations-Section\n",
    "ABBREVIATION_TITLE = \"List of Abbrevations\"\n",
    "ABBREVIATION_HEADLINE_TAG = \"H6\"\n",
    "\n",
    "# Trends-Section\n",
    "TRENDS_TITLE = \"Trends\"\n",
    "TRENDS_DESCRIPTION = \"\"\n",
    "TRENDS_SUB_SECTION_HEADLINE_TAG = \"H2\"\n",
    "TRENDS_SUB_SECTION_SLOGAN_TAG = \"H3\"\n",
    "TRENDS_SUB_SECTION_AREA_HEADLINE_TAG = \"H4\" # Trend Drivers, Trend Facts ... \n",
    "TRENDS_SUB_SECTION_AREA_IMPACT_HEADLINE = \"Impact on the construction industry\"\n",
    "\n",
    "# Sources-Section\n",
    "SOURCES_TITLE = \"Sources\"\n",
    "SOURCES_DESCRIPTION = \"\"\n",
    "SOURCES_KEY_TAG = \"H6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This pipeline downloads the data from the googel spread sheet and then replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Help functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Text formatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    text = text.replace(\"&\", \"&amp;\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text_test():\n",
    "    print(sanitize_text(\"Hello & World\") == \"Hello &amp; World\")\n",
    "\n",
    "#sanitize_text_test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xml_list(text):\n",
    "    result = \"<List>\\n\"\n",
    "    li = [s.strip() for s in text.splitlines()]\n",
    "    for l in li:\n",
    "        result += \"<List-Element>\" + l+ \"</List-Element>\\n\"\n",
    "\n",
    "    result += \"</List>\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_xml_list_test():\n",
    "    print(generate_xml_list(\"Hello World \\n hello / Seb \\n hello CDTM\\n\"))\n",
    "    \n",
    "#generate_xml_list_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Find and replace author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author_and_replace(text):    \n",
    "    counter = 0\n",
    "    authors = dict()\n",
    "    p = re.compile(\"\\[([a-zäöüÄÖÜA-Z_0-9]*)\")\n",
    "    for match in p.finditer(text):\n",
    "        key = match.group(1)\n",
    "        if key not in authors and len(key) > 0:\n",
    "            counter += 1\n",
    "            authors[key] = counter\n",
    "    \n",
    "    # print(authors)\n",
    "            \n",
    "    for key, value in authors.items():\n",
    "        text = text.replace(\"[\"+str(key), \"[\"+str(value))\n",
    "        \n",
    "    return (text, authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_author_and_replace_test():\n",
    "    test = \"The side bar include [] [KRAUZ, p.22] a Cheatsheet, full [KRAUZ] Reference, sults with the Tools below [SEB], [KAYA]. Replace & List outp [HASE]. [KRAUZ] [KRAUZ] [KRAUZ] [KRAUZ]\"\n",
    "    text, authors = find_author_and_replace(test)\n",
    "    #print(text)\n",
    "    #print(authors)\n",
    "\n",
    "    \n",
    "find_author_and_replace_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data from the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.countingcalculi.com/explanations/google_sheets_and_jupyter_notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = 'https://www.googleapis.com/auth/spreadsheets.readonly'\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "SPREADSHEET_ID = '16jza4slLRK4Fe3-O_f410P_-WZBe5EN-fmq_OW3HJNQ'\n",
    "RANGE_NAME = 'Trends'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_google_sheets():\n",
    "    scope = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name('./credentials.json', scope)\n",
    "    # print(credentials)\n",
    "    gc = gspread.authorize(credentials)\n",
    "    \n",
    "    book = gc.open_by_key(SPREADSHEET_ID)\n",
    "    return book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = load_data_from_google_sheets()\n",
    "# print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends\n",
    "\n",
    "Generate the trends from the sheet and transform it into the XML structure\n",
    "\n",
    "```\n",
    "<Trends-Section>\n",
    "<List>\n",
    "<List-Element>Technology Trends</List-Element>\n",
    "<List-Element>Societal &amp; Environmental Trends</List-Element>\n",
    "</List>\n",
    "<Trends-Sub-Sections>\n",
    "<Trends-Sub-Section>\n",
    "<H1>AI</H1>\n",
    "<H3>SUBRTITLE</H3>\n",
    "<Text>Intro text for bla bla</Text>\n",
    "<Trends>\n",
    "<Trend>\n",
    "<H2>Trend 1 Title</H2>\n",
    "<H3>Slogan</H3>\n",
    "<Text>\n",
    "Intro text\n",
    "<H4>Facts</H4>\n",
    "<List>\n",
    "<List-Element>Hello World</List-Element>\n",
    "<List-Element>Hello CDTM!</List-Element>\n",
    "<List-Element>Hello Sebastian</List-Element>\n",
    "...\n",
    "</List>\n",
    "</Text>\n",
    "</Trend>\n",
    "</Trends>\n",
    "</Trends-Sub-Section>\n",
    "...\n",
    "</Trends-Sub-Sections>\n",
    "\n",
    "\n",
    "<Abbreviation><H6>BIM</H6>Building information modeling</Abbreviation>\n",
    "<Abbreviation><H6>LCC</H6>Life Cycle Costing</Abbreviation>\n",
    "...\n",
    "</Abbreviations>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trends(book):\n",
    "    # Init XML structure\n",
    "    result = \"<Trends-Section>\\n\";\n",
    "    result += \"<H1>\"+TRENDS_TITLE+\"</H1>\\n\";\n",
    "    # Add description if necessary\n",
    "    if len(TRENDS_DESCRIPTION) > 0:\n",
    "        result += \"<Text>\"+TRENDS_DESCRIPTION+\"</Text>\\n\";\n",
    "    \n",
    "    # Init list of trend sections\n",
    "    result_trend_list = \"<List>\\n\"\n",
    "    \n",
    "    # Load trends\n",
    "    # Trends_intro\n",
    "    worksheet = book.worksheet(\"Trend_Intro\")\n",
    "    table = worksheet.get_all_values()\n",
    "    ##Convert table data into a dataframe\n",
    "    df_trends_intro = pd.DataFrame(table[1:], columns=table[0])\n",
    "    # print(df_trends_intro)\n",
    "\n",
    "    worksheet = book.worksheet(\"Trends\")\n",
    "    table = worksheet.get_all_values()\n",
    "    # Convert table data into a dataframe\n",
    "    df_trends = pd.DataFrame(table[2:], columns=table[0])\n",
    "    # print(df_trends)\n",
    "    \n",
    "    # Start with sub sections\n",
    "    result_sub_sections = \"<Trends-Sub-Sections>\\n\"\n",
    "    # Iterate over the trend intro\n",
    "    for index, row in islice(df_trends_intro.iterrows(), 0, None):\n",
    "        # Grab the key and values\n",
    "        key = sanitize_text(row[3])\n",
    "        intro_text = sanitize_text(row[4])\n",
    "        intro_responsible = sanitize_text(row[2])\n",
    "        \n",
    "        # Init the trend sub section\n",
    "        result_trend_sub_section = '<Trends-Sub-Section title=\"'+key+'\">\\n';\n",
    "        \n",
    "        result_trend_sub_section += \"<H1>\"+ key + \"</H1>\\n\"\n",
    "        result_trend_sub_section += '<Text responsible=\"'+intro_responsible+'\">'+ intro_text + \"</Text>\\n\"\n",
    "        \n",
    "        # Add the trend to the overview list\n",
    "        result_trend_list += \"<List-Element>\" + key + \"</List-Element>\\n\"\n",
    "        \n",
    "        # Start adding the trends\n",
    "        result_trend_sub_section += '<Trends>\\n'\n",
    "        \n",
    "        for trend_index, trend_row in df_trends.loc[df_trends['Sub-Section'] == row[3]].iterrows():\n",
    "            trend_title = sanitize_text(trend_row[2])\n",
    "            trend_slogan = sanitize_text(trend_row[7])\n",
    "            trend_intro = sanitize_text(trend_row[9])\n",
    "            trend_facts = sanitize_text(trend_row[11])\n",
    "            trend_drivers = sanitize_text(trend_row[13])\n",
    "            trend_challanges = sanitize_text(trend_row[15])\n",
    "            trend_impact = sanitize_text(trend_row[17])\n",
    "            trend_responsible = sanitize_text(trend_row[5])\n",
    "            \n",
    "            result_trend = '<Trend responsible=\"'+trend_responsible+'\">\\n'            \n",
    "            \n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_HEADLINE_TAG+\">\" + trend_title + \"</\"+TRENDS_SUB_SECTION_HEADLINE_TAG+\">\\n\"\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_SLOGAN_TAG+\">\" + trend_slogan + \"</\"+TRENDS_SUB_SECTION_SLOGAN_TAG+\">\\n\"\n",
    "            result_trend += \"<Text>\\n\"\n",
    "            # Trend intro\n",
    "            result_trend += trend_intro + \"\\n\"\n",
    "            # Trend Facts\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"Facts:\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_facts) +\"\\n\"\n",
    "            # Trend Key Drivers\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"Key Drivers:\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_drivers) +\"\\n\"\n",
    "            # Trend Challenges\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"Challenges:\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_challanges) +\"\\n\"\n",
    "            # Trend Impact Headline\n",
    "            result_trend += \"<\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+TRENDS_SUB_SECTION_AREA_IMPACT_HEADLINE +\":\"+\"</\"+TRENDS_SUB_SECTION_AREA_HEADLINE_TAG+\">\"+\"\\n\"\n",
    "            result_trend += generate_xml_list(trend_impact) +\"\\n\"\n",
    "            # Trend Impact Text\n",
    "            result_trend += \"</Text>\\n\"\n",
    "            result_trend += \"</Trend>\\n\"\n",
    "            result_trend_sub_section += result_trend\n",
    "        \n",
    "        # Close the trend section\n",
    "        result_trend_sub_section += '</Trends>\\n'\n",
    "    \n",
    "        \n",
    "    \n",
    "        # Close the trend sub section\n",
    "        result_trend_sub_section += \"</Trends-Sub-Section>\\n\";\n",
    "\n",
    "        # Add it to the result\n",
    "        result_sub_sections += result_trend_sub_section;\n",
    "\n",
    "    result_sub_sections += \"</Trends-Sub-Sections>\"\n",
    "    \n",
    "    result_trend_list += \"</List>\"\n",
    "    \n",
    "    # Add the elements to the result object\n",
    "    result += result_trend_list + \"\\n\"\n",
    "    result += result_sub_sections + \"\\n\"\n",
    "    result += \"</Trends-Section>\\n\";\n",
    "    return result  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenarios\n",
    "\n",
    "Generate scenario XML from excel sheet\n",
    "```\n",
    "<Scenarios>\n",
    "  <Scenario>\n",
    "    <Title>\n",
    "    <H1>shitty title</H1>\n",
    "    </Title>\n",
    "    \n",
    "    <Subtitle>\n",
    "    <H2>shitty subtitle</H2>\n",
    "    </Subtitle>\n",
    "    \n",
    "    <Text>\n",
    "    sometext\n",
    "    </Text>\n",
    "  </Scenario>\n",
    "  <Scenario>\n",
    "      .\n",
    "      .\n",
    "      .\n",
    "  </Scenario>\n",
    "  ...\n",
    "  ...\n",
    "  ...\n",
    "  <Scenario>\n",
    "      .\n",
    "      .\n",
    "      .\n",
    "  </Scenario>\n",
    "</Scenarios>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify_sign_posts(text):\n",
    "    li = [s.strip() for s in text.splitlines()]\n",
    "    root = etree.Element(\"Sign-Posts\")\n",
    "    for item in li:\n",
    "        if item == \"\" or item == \"\\n\":\n",
    "            continue\n",
    "        post = etree.Element(\"Sign-Post\")\n",
    "        post.text = item\n",
    "        root.append(post)\n",
    "    return root\n",
    "        \n",
    "def generate_scenario_xml(book):\n",
    "    scenariosheet = book.worksheet(\"Scenarios\")\n",
    "    table = scenariosheet.get_all_values()\n",
    "    df_scenarios = pd.DataFrame(table[2:], columns=table[0])\n",
    "    \n",
    "    # Section\n",
    "    scenarios_section = etree.Element(\"Scenarios-Section\")\n",
    "    \n",
    "    # Add headline\n",
    "    h1 = etree.Element(\"H1\")\n",
    "    h1.text = \"Scenarios\"\n",
    "    scenarios_section.append(h1)\n",
    "    \n",
    "    # Add scenarios list\n",
    "    scenarios_list = etree.Element(\"List\")\n",
    "    for index, row in islice(df_scenarios.iterrows(), 0, None):        \n",
    "        scenarios_list_element = etree.Element(\"List-Element\")\n",
    "        scenarios_list_element.text = sanitize_text(row[2])\n",
    "        scenarios_list.append(scenarios_list_element)\n",
    "    \n",
    "    scenarios_section.append(scenarios_list)\n",
    "    \n",
    "    # Build the XML tree\n",
    "    root = etree.Element(\"Scenarios\")\n",
    "    \n",
    "    for index, row in islice(df_scenarios.iterrows(), 0, None):\n",
    "        scenario = etree.Element(\"Scenario\")\n",
    "        \n",
    "        title = etree.Element(\"Title\")\n",
    "        h1 = etree.Element(\"H1\")\n",
    "        h1.text = sanitize_text(row[2])\n",
    "        title.append(h1)\n",
    "        scenario.append(title)\n",
    "        \n",
    "        subtitle = etree.Element(\"Subtitle\")\n",
    "        h2 = etree.Element(\"H2\")\n",
    "        h2.text =  sanitize_text(row[5])\n",
    "        subtitle.append(h2)\n",
    "        scenario.append(subtitle)\n",
    "        \n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = sanitize_text(row[7])\n",
    "        scenario.append(text)\n",
    "        \n",
    "        #sign_posts = etree.Element(\"sign_posts\")\n",
    "        #sign_posts.text = generate_xml_list(sanitize_text(row[9]))\n",
    "        scenario.append(listify_sign_posts(sanitize_text(row[9])))\n",
    "        \n",
    "        root.append(scenario)\n",
    "        \n",
    "        scenarios_section.append(root)\n",
    "        \n",
    "    return etree.tostring(scenarios_section, encoding=\"unicode\", method='xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ideas\n",
    "\n",
    "Generate Ideas XML from excel sheet\n",
    "```\n",
    "<Ideas>\n",
    "    <Idea>\n",
    "        <Title>\n",
    "            <H1>\n",
    "            </H1>\n",
    "        </Title>\n",
    "        <Subtitle>\n",
    "            <H2>\n",
    "            </H2>\n",
    "        </Subtitle>\n",
    "        <Value-Proposition-Canvas>\n",
    "            <Item>\n",
    "            </Item>\n",
    "            <Item>\n",
    "            </Item>\n",
    "        </Value-Proposition-Canvas>\n",
    "        <Value-Proposition-Text>\n",
    "            <Text>\n",
    "            </Text>\n",
    "        </Value-Proposition-Text>\n",
    "        ...\n",
    "        ...\n",
    "        ...\n",
    "    </Idea>\n",
    "    ...\n",
    "    ...\n",
    "</Ideas>\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listify_canvas(text, root_tag):\n",
    "    li = [s.strip() for s in text.splitlines()]\n",
    "    root = etree.Element(root_tag)\n",
    "    root_list = etree.Element(\"List\")\n",
    "    for item in li:\n",
    "        if item == \"\" or item == \"\\n\":\n",
    "            continue\n",
    "        post = etree.Element(\"List-Element\")\n",
    "        post.text = BULLET_ICON + item\n",
    "        root_list.append(post)\n",
    "    root.append(root_list)\n",
    "    return root\n",
    "\n",
    "def generate_ideas(book):\n",
    "    ideasheet = book.worksheet(\"Ideation\")\n",
    "    table = ideasheet.get_all_values()\n",
    "    df_ideas = pd.DataFrame(table[3:])#, columns=table[3])\n",
    "    #print(df_ideas.head)\n",
    "    #df_ideas.set_index('Title',inplace=True)\n",
    "    df_ideas = df_ideas.transpose()\n",
    "    df_ideas = df_ideas[1:]\n",
    "    #print(df_ideas.shape)#['Title'])\n",
    "    # Build the XML tree\n",
    "    ideas_section = etree.Element(\"Ideas-Section\")\n",
    "    \n",
    "    # Add headline\n",
    "    h1 = etree.Element(\"H1\")\n",
    "    h1.text = \"Ideas\"\n",
    "    ideas_section.append(h1)\n",
    "    \n",
    "    # Add ideas list\n",
    "    ideas_list = etree.Element(\"List\")\n",
    "    for index, row in islice(df_ideas.iterrows(), 0, None):        \n",
    "        ideas_list_element = etree.Element(\"List-Element\")\n",
    "        ideas_list_element.text = row[0]\n",
    "        ideas_list.append(ideas_list_element)\n",
    "    \n",
    "    \n",
    "    ideas_section.append(ideas_list)\n",
    "    \n",
    "    # Ideas\n",
    "    ideas = etree.Element(\"Ideas\")   \n",
    "    \n",
    "    for index, row in islice(df_ideas.iterrows(), 0, None):\n",
    "        if (row[0]) == \"\":\n",
    "            continue\n",
    "        idea = etree.Element(\"Idea\")\n",
    "        \n",
    "        # Title\n",
    "        title = etree.Element(\"Title\")\n",
    "        heading1 = etree.Element(\"H1\")\n",
    "        heading1.text = row[0]\n",
    "        title.append(heading1)\n",
    "        idea.append(title)\n",
    "        \n",
    "        #subtitle\n",
    "        sub = etree.Element(\"Subtitle\")\n",
    "        h2 = etree.Element(\"H2\")\n",
    "        h2.text = row[1]\n",
    "        sub.append(h2)\n",
    "        idea.append(sub)\n",
    "        \n",
    "        #intro\n",
    "        intro = etree.Element(\"Intro\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[2]\n",
    "        intro.append(text)\n",
    "        idea.append(intro)\n",
    "        \n",
    "        #Value Proposition_Canvas\n",
    "        #vpc = etree.Element(\"Value_Proposition_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[4]\n",
    "        #vpc.append(listify_canvas(row[4], \"Value_Proposition_Canvas\"))\n",
    "        idea.append(listify_canvas(row[4], \"Value-Proposition-Canvas\"))\n",
    "        \n",
    "        #Value Proposition_Text\n",
    "        vpt = etree.Element(\"Value-Proposition-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[5]\n",
    "        vpt.append(text)\n",
    "        idea.append(vpt)        \n",
    "        \n",
    "        #Customer Relationships_Canvas\n",
    "        #crc = etree.Element(\"Customer_Relationships_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[6]\n",
    "        #crc.append(text)\n",
    "        idea.append(listify_canvas(row[6], \"Customer-Relationships-Canvas\"))  \n",
    "        \n",
    "        #Customer Relationships_Text\n",
    "        crt = etree.Element(\"Customer-Relationships-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[7]\n",
    "        crt.append(text)\n",
    "        idea.append(crt)  \n",
    "        \n",
    "        #Channels_Canvas\n",
    "        #cc = etree.Element(\"Channels_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[8]\n",
    "        #cc.append(text)\n",
    "        idea.append(listify_canvas(row[8], \"Channels-Canvas\"))\n",
    "        \n",
    "        #Channels_Text\n",
    "        ct = etree.Element(\"Channels-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[9]\n",
    "        ct.append(text)\n",
    "        idea.append(ct)\n",
    "        \n",
    "        #Key Resources_Canvas\n",
    "        #krc = etree.Element(\"Key_Resources_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[10]\n",
    "        #krc.append(text)\n",
    "        idea.append(listify_canvas(row[10], \"Key-Resources-Canvas\"))\n",
    "        \n",
    "        #Key Resources_Text\n",
    "        krt = etree.Element(\"Key-Resources-Text\")\n",
    "        text = etree.Element(\"text\")\n",
    "        text.text = row[11]\n",
    "        krt.append(text)\n",
    "        idea.append(krt)\n",
    "        \n",
    "        #Key Activities_Canvas\n",
    "        #kac = etree.Element(\"Key_Activities_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[12]\n",
    "        #kac.append(text)\n",
    "        idea.append(listify_canvas(row[12], \"Key-Activities-Canvas\"))\n",
    "        \n",
    "        #Key Activities_Text\n",
    "        kat = etree.Element(\"Key-Activities-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[13]\n",
    "        kat.append(text)\n",
    "        idea.append(kat)\n",
    "        \n",
    "        #Revenue Streams_Canvas\n",
    "        #rsc = etree.Element(\"Revenue_Streams_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[14]\n",
    "        #rsc.append(text)\n",
    "        idea.append(listify_canvas(row[14], \"Revenue-Streams-Canvas\"))\n",
    "        \n",
    "        #Revenue Streams_Text\n",
    "        rst = etree.Element(\"Revenue-Streams-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[15]\n",
    "        rst.append(text)\n",
    "        idea.append(rst)\n",
    "        \n",
    "        #Key Partners_Canvas\n",
    "        #kpc = etree.Element(\"Key_Partners_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[16]\n",
    "        #kpc.append(text)\n",
    "        idea.append(listify_canvas(row[16], \"Key-Partners-Canvas\"))\n",
    "        \n",
    "        #Key Partners_Text\n",
    "        kpt = etree.Element(\"Key-Partners-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[17]\n",
    "        kpt.append(text)\n",
    "        idea.append(kpt)\n",
    "        \n",
    "        #Customer Segmentation_Canvas\n",
    "        #csc = etree.Element(\"Customer_Segmentation_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[18]\n",
    "        #csc.append(text)\n",
    "        idea.append(listify_canvas(row[18], \"Customer-Segmentation-Canvas\"))\n",
    "        \n",
    "        #Customer Segmentation_Text\n",
    "        cst = etree.Element(\"Customer-Segmentation-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[19]\n",
    "        cst.append(text)\n",
    "        idea.append(cst)\n",
    "        \n",
    "        #Cost Structure_Canvas\n",
    "        #csc = etree.Element(\"Cost Structure_Canvas\")\n",
    "        #text = etree.Element(\"text\")\n",
    "        #text.text = row[20]\n",
    "        #csc.append(text)\n",
    "        idea.append(listify_canvas(row[20], \"Cost-Structure-Canvas\"))\n",
    "        \n",
    "        #Cost Structure_Text\n",
    "        cst = etree.Element(\"Cost-Structure-Text\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[21]\n",
    "        cst.append(text)\n",
    "        idea.append(cst)\n",
    "        \n",
    "        #Senario Fit_1\n",
    "        sf = etree.Element(\"Senario-Fit-1\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[23]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        #Senario Fit_2\n",
    "        sf = etree.Element(\"Senario-Fit-2\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[24]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        #Senario Fit_3\n",
    "        sf = etree.Element(\"Senario-Fit-3\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[25]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        #Senario Fit_4\n",
    "        sf = etree.Element(\"Senario-Fit-4\")\n",
    "        text = etree.Element(\"Text\")\n",
    "        text.text = row[26]\n",
    "        sf.append(text)\n",
    "        idea.append(sf)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ideas.append(idea)\n",
    "        # print(row[0])\n",
    "        \n",
    "        ideas_section.append(ideas)\n",
    "        \n",
    "    return etree.tostring(ideas_section, encoding=\"unicode\", method='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(generate_abbrevations(book))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abbrevations\n",
    "\n",
    "Generate the abbrevations from the sheet and transform it into the XML structure\n",
    "\n",
    "```\n",
    "<Abbreviations>\n",
    "<Abbreviation><H6>AI</H6>Artificial Intelligence</Abbreviation>\n",
    "<Abbreviation><H6>BIM</H6>Building information modeling</Abbreviation>\n",
    "<Abbreviation><H6>LCC</H6>Life Cycle Costing</Abbreviation>\n",
    "...\n",
    "</Abbreviations>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_abbrevations(book):\n",
    "    worksheet = book.worksheet(\"Abreviations\")\n",
    "    table = worksheet.get_all_values()\n",
    "    ##Convert table data into a dataframe\n",
    "    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "    # Init XML structure\n",
    "    result = \"<Abbreviations-Section>\\n\";\n",
    "    result += \"<H1>\"+ABBREVIATION_TITLE+\"</H1>\\n\";\n",
    "    result += \"<Abbreviations>\\n\";\n",
    "    # Iterate over the rows\n",
    "    for index, row in islice(df.iterrows(), 1, None):\n",
    "        # Grab the key and values\n",
    "        key = sanitize_text(row[0])\n",
    "        val = sanitize_text(row[1])\n",
    "        # Create a xml string\n",
    "        result += \"<Abbreviation><\"+ABBREVIATION_HEADLINE_TAG+\">\" + key + \"</\"+ABBREVIATION_HEADLINE_TAG+\">\" + val + \"</Abbreviation>\\n\"\n",
    "    # Add closing tag\n",
    "    result += \"</Abbreviations>\\n\";\n",
    "    result += \"</Abbreviations-Section>\\n\";\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "Generate the sources from the sheet and transform it into the XML structure.\n",
    "Order the sources by the apperance.\n",
    "\n",
    "```\n",
    "<Sources-Section>\n",
    "<H1>Source</H1>\n",
    "<Sources>\n",
    "<Source>\n",
    "<H6>1</H6> Sebastians Report 2017 ....\n",
    "</Source>\n",
    "...\n",
    "</Sources>\n",
    "</Sources-Section>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sources(book, map_hash_source):\n",
    "    errors = []\n",
    "    # invert the mapping NUMBER -> HASH\n",
    "    map_number_hash = {v: k for k, v in map_hash_source.items()}\n",
    "    \n",
    "    # Init an array with the size of the sources\n",
    "    sources = [(\"\",\"\")]*len(map_hash_source)\n",
    "       \n",
    "    worksheet = book.worksheet(\"Sources\")\n",
    "    table = worksheet.get_all_values()\n",
    "    # Convert table data into a dataframe\n",
    "    df = pd.DataFrame(table[1:], columns=table[0])\n",
    "    # print(df_trends)\n",
    "    \n",
    "    # Start with sub sections\n",
    "    result = \"<Sources-Sections>\\n\"\n",
    "    result += \"<H1>\"+SOURCES_TITLE+\"</H1>\\n\"\n",
    "    result += \"<Text>\"+SOURCES_DESCRIPTION+\"</Text>\\n\"\n",
    "    # Start with the list\n",
    "    result += \"<Sources>\\n\"\n",
    "    # Iterate over the sources array\n",
    "    for index, row in islice(df.iterrows(), 1, None):\n",
    "        key = sanitize_text(row[0])\n",
    "        responsible = sanitize_text(row[2])\n",
    "        val = sanitize_text(row[4])\n",
    "        if key in map_hash_source:\n",
    "            # Find the number of the source\n",
    "            source_index = map_hash_source[key]-1\n",
    "            # Add the value of the source to the right order of the array\n",
    "            sources[source_index] = (val, responsible)\n",
    "        else:\n",
    "            err = {\n",
    "                \"type\": \"Source not used\",\n",
    "                \"responsible\": responsible,\n",
    "                \"key\": key,\n",
    "            }\n",
    "            errors.append(err)\n",
    "        \n",
    "    # Iterate of the ordered source array and genrate the xml\n",
    "    for index, (source, responsible) in enumerate(sources):\n",
    "        if (len(source) == 0):\n",
    "            err = {\n",
    "                \"type\": \"Source not declared\",\n",
    "                \"responsible\": \"\",\n",
    "                \"key\": map_number_hash[index+1],\n",
    "            }\n",
    "            errors.append(err)\n",
    "        else:\n",
    "            result += '<Source responsible=\"'+responsible+'\">\\n'\n",
    "            result += \"<\" + SOURCES_KEY_TAG + \">\" + str(index+1) + \"</\" + SOURCES_KEY_TAG + \"> \"\n",
    "            result += source\n",
    "            result += \"\\n\"\n",
    "            result += \"</Source>\\n\"\n",
    "    \n",
    "    # Close the xml tags\n",
    "    result += \"</Sources>\\n\"    \n",
    "    result += \"</Sources-Sections>\\n\"\n",
    "    \n",
    "    return result, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    book = load_data_from_google_sheets()\n",
    "    xml = \"\"\n",
    "    # Add Abbreviations\n",
    "    xml += generate_abbrevations(book)\n",
    "    # Add Trends\n",
    "    xml += generate_trends(book)\n",
    "    # Add Scenarios\n",
    "    xml += generate_scenario_xml(book)\n",
    "    # Add Ideation\n",
    "    xml += generate_ideas(book)\n",
    "    # Add Sources    \n",
    "    # Replace the citation\n",
    "    xml, authors = find_author_and_replace(xml)\n",
    "    print(authors)\n",
    "    sources, errors = generate_sources(book, authors)\n",
    "    xml += sources\n",
    "    # Wrap the root object arround all\n",
    "    xml = '<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n<Root>\\n' + xml + '</Root>'\n",
    "    # print(xml)\n",
    "    return xml, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AGA16': 1, 'ROL16': 2, 'SCHO16': 3, 'GLA17': 4, 'SON10': 5, 'SAF16': 6, '7': 7, 'SOL18': 8, 'FUC18': 9, 'REN16': 10, 'WIS16': 11, 'WAN16': 12, 'GOL18': 13, 'PET13': 14, 'ECO12': 15, 'NÄT17': 16, 'GOS16': 17, 'JBK07': 18, 'BOR18': 19, 'BOC15': 20, 'BRE17': 21, 'GAR18': 22, 'SCH15': 23, 'JON18': 24, 'MIT18': 25, 'AKB17': 26, 'AWO18': 27, 'DAR11': 28, 'RUF03': 29, 'EKS17': 30, 'STAR14': 31, 'DGU16': 32, 'DGA18': 33, 'GARD18': 34, 'ABI15': 35, 'KOR17': 36, 'HOF16': 37, 'WEB18': 38, 'STA14': 39, '16': 40, 'WHI14': 41, 'SMI18': 42, 'CAR17': 43, 'ANT17': 44, 'LUC17': 45, 'MUR18': 46, 'PRO17': 47, 'NEL18': 48, 'TRA17': 49, 'VIE18': 50, 'BRA15': 51, 'PHA17': 52, 'JER15': 53, 'DON18': 54, 'GOU17': 55, 'BAR17': 56, 'CHR18': 57, 'WOY18': 58, 'SCHO18': 59, 'COL13': 60, 'REP16': 61, 'ASS17': 62, 'OCH13': 63, 'VER18': 64, 'LAN18': 65, 'ORA13': 66, 'SIN00': 67, 'CPS17': 68, 'GAL17': 69, 'DES18': 70, 'WEL00': 71, 'WEW14': 72, 'JAC17': 73, 'GEL18': 74, 'HAN18': 75, 'SPA17': 76, 'PWC18': 77, 'ING77': 78, 'SCHEU16': 79, 'TAE18': 80, 'ZUK18': 81, 'ADR15': 82, 'BCG00': 83, 'GIN12': 84, 'BOA15': 85, 'BIE15': 86, 'BRE18': 87, 'HOL18': 88, 'BRA16': 89, 'CBR18': 90, 'DUI17': 91, 'WOH18': 92, 'DBR17': 93, 'HEI12': 94, 'MOR17': 95, 'BOA05': 96, 'MAE11': 97, 'DEM11': 98, 'BRA05': 99, 'TRO15': 100, 'SOD18': 101, 'GAL16': 102, 'OZC15': 103, 'MAN16': 104, 'LIN15': 105, 'TNS16': 106, 'XUE14': 107, 'EUC17': 108, 'MCM17': 109, 'BRO17': 110, 'CAL17': 111, 'SMO02': 112, 'GIL11': 113, 'OBO17': 114, 'LEI06': 115, 'KOL15': 116, 'NAH11': 117, 'LIN12': 118, 'EUR16': 119, 'STA18': 120, 'BOC14': 121, 'KHA16': 122, 'BAR99': 123, 'PAT02': 124, 'RAH14': 125, 'UNI09': 126, 'ALL15': 127, 'SIN09': 128, 'LOC06': 129, 'PET16': 130, 'BNP16': 131, 'KFW17': 132, 'CAJ13': 133, 'MAT16': 134, 'BRO14': 135, 'BEY11': 136, 'BUT05': 137, 'BRU16': 138, 'BAL15': 139, 'ECK18': 140, 'DW16': 141, 'BFA18': 142, 'VOG15': 143, 'HAR17': 144, 'BAR14': 145, 'TRI15': 146, 'HEI16': 147, 'SOL11': 148, 'BOV12': 149, 'DPA14': 150, 'REH16': 151, 'BER11': 152, 'AAR18': 153, 'FWB18': 154, 'CSU17': 155, 'BAY15': 156, 'BUE18': 157, 'ALB13': 158, 'DER18': 159, '40': 160, 'HMG12': 161, 'EGG13': 162, 'GOG18': 163, 'CCS17': 164, 'MCK18_2': 165, 'DIT14': 166, 'BMUB16': 167, 'EUAR08': 168, 'BR17': 169, 'KRWG12': 170, 'KWB14': 171, 'STA16': 172, 'KWB17': 173, 'ST16': 174, 'DHZ18': 175, 'DNR18': 176, 'EUC16': 177, 'BMW18': 178, 'BMW15': 179, 'BMW14': 180, 'MIN15': 181, 'WOH14': 182, 'EUT17': 183, 'BUN02': 184, 'LEH14': 185, 'SHA17': 186, 'DER15': 187, 'EUT': 188, 'SZA94': 189, 'DEL18': 190, 'THA18': 191, 'HEC18': 192, 'PRI17': 193, 'CMS18': 194, 'FOX16': 195, 'EUC18b': 196, 'INT18': 197, 'HDB15b': 198, 'BBF18': 199, 'MGH10': 200, 'EUR17': 201, 'ZDB17': 202, 'OCC17': 203, 'HEL17': 204, 'CMS17': 205, 'BUI18': 206, 'WAG18': 207, 'HEC17': 208, 'BAU15': 209, 'WAC17': 210, 'STAT17': 211, 'GOR18': 212, 'DOR18': 213, 'KOC17': 214, 'BAU18': 215, 'TRA18': 216, 'TEC17': 217, 'PHI16': 218, 'TEC18': 219, 'OEC16': 220, 'NIE18': 221, 'PLB18': 222, 'ESC17': 223, 'HOF17': 224, 'WEIT18': 225, 'STU15': 226, 'GAB18': 227, 'DEL15': 228, 'RAD17': 229, 'CON15': 230, 'INS18': 231, 'CEU18': 232, 'GUN18': 233, 'EUR18': 234, 'DEL17': 235, 'WEI18': 236, 'KRA18': 237, 'WEI18_2': 238, 'HAG15': 239, 'DEU13': 240, 'WEI18_3': 241, 'CIT18': 242, 'SCH16': 243, 'FAI18': 244, 'ETT18': 245, 'FAE18': 246, 'SCH18': 247, 'MCK17': 248, 'WEF17': 249, 'HER14': 250, 'BAG15': 251, 'HON16': 252, 'MGH11': 253, 'WON03': 254, 'NRC09': 255, 'CBI17': 256, 'MBÖ18': 257, 'LAW05': 258, 'BDF17': 259, 'STB17': 260, 'BLO17': 261, 'BIS17': 262, 'ABA17': 263, 'MAR18': 264, 'WDM18': 265, 'LEG13': 266, 'BRE14': 267, 'WIN18': 268, 'PEL06': 269, 'STE13': 270, 'WOU05': 271, 'BEC14': 272, 'ARA10': 273, 'ARD97': 274, 'BIL06': 275, 'EAD13': 276, 'OSU04': 277, 'SCH11': 278, 'CLE18': 279, 'HAM18': 280, 'STI15': 281, 'OES16': 282, 'see': 283, 'STU93': 284, 'JOH98': 285, 'DAV94': 286, 'AND86': 287, 'CBI17_2': 288, 'ZHU16': 289, 'DAU16': 290, 'MCK18': 291, 'NAV16': 292, 'AZE18': 293, 'HAM16': 294, 'Src': 295, 'VAN16': 296, 'MEZ16': 297, 'SCH17': 298, 'STAT16': 299, 'CAG11': 300, 'DOS10': 301, 'ECC81': 302, 'POW87': 303, 'AKI07': 304, 'BOD00': 305, 'DUC16': 306, 'RAJ17': 307, 'RID17': 308, 'CAS18': 309, 'GAN17': 310, 'France': 311, 'US': 312, 'HAA17': 313, 'GRA17': 314}\n"
     ]
    }
   ],
   "source": [
    "# xml, err = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
